"""
Constants used throughout the Audio2DTX application.
"""

from typing import Dict, List

# Audio processing constants
SAMPLE_RATE = 44100
HOP_LENGTH = 512
N_FFT = 2048
N_MELS = 128

# Supported audio formats
SUPPORTED_AUDIO_FORMATS = ['.mp3', '.wav', '.flac', '.ogg', '.m4a']

# DTX format constants
DTX_RESOLUTION = 192  # DTX resolution per quarter note
DTX_CHANNELS = {
    'hi-hat-close': '11',
    'snare': '12', 
    'kick': '13',
    'tom-high': '14',
    'tom-low': '15',
    'ride': '16',
    'tom-floor': '17',
    'hi-hat-open': '18',
    'ride-bell': '19',
    'crash': '1A'
}

# Instrument mappings
DRUM_CLASSES = {
    0: 'hi-hat-close',
    1: 'snare', 
    2: 'kick',
    3: 'tom-high',
    4: 'tom-low',
    5: 'ride',
    6: 'tom-floor',
    7: 'hi-hat-open',
    8: 'ride-bell',
    9: 'crash'
}

CHANNEL_TO_INT = {v: k for k, v in DRUM_CLASSES.items()}
INT_TO_CHANNEL = {k: DTX_CHANNELS[v] for k, v in DRUM_CLASSES.items()}

# Time signatures
VALID_TIME_SIGNATURES = ['4/4', '3/4', '6/8', '2/4', '5/4']

# Default metadata
DEFAULT_METADATA = {
    'artist': 'Unknown Artist',
    'author': 'Audio2DTX',
    'difficulty': 5,
    'use_original_bgm': True,
    'time_signature': '4/4',
    'genre': 'Rock',
    'comment': 'Auto-generated by Audio2DTX'
}

# Onset detection methods
ONSET_DETECTION_METHODS = [
    'energy',
    'hfc', 
    'complex',
    'phase',
    'specdiff'
]

# Classification tracks
AVAILABLE_TRACKS = {
    'track3': 'Magenta-Only Classification',
    'track4': 'Advanced Spectral Features',
    'track5': 'Multi-Scale Temporal Analysis', 
    'track6': 'Real-Time Few-Shot Learning',
    'track7': 'Ensemble of Specialized Models',
    'track8': 'Data Augmentation and Preprocessing',
    'track9': 'Ultimate Rock/Metal Hybrid'
}

# Feature extraction constants
N_MFCC = 13
N_CHROMA = 12
N_CONTRAST = 7
N_TONNETZ = 6

# Frequency bands for analysis (Hz)
FREQ_BANDS = {
    'low': (20, 200),      # Kick, low toms
    'mid': (200, 2000),    # Snare, mid toms  
    'high': (2000, 8000)   # Hi-hats, cymbals
}

# Multi-scale temporal analysis windows (ms)
TEMPORAL_SCALES = [25, 50, 100, 200]

# Confidence thresholds
MIN_CONFIDENCE = 0.1
DEFAULT_CONFIDENCE = 0.6
HIGH_CONFIDENCE = 0.8

# Service endpoints
DEFAULT_MAGENTA_URL = 'http://magenta-service:5000'
MAGENTA_ENDPOINTS = {
    'health': '/health',
    'classify': '/classify-drums',
    'info': '/info'
}

# File paths
MODEL_FILE = 'PredictOnset.h5'
TEMPLATE_FILE = 'SimfilesTemplate.zip'
INPUT_DIR = '/app/input'
OUTPUT_DIR = '/app/output'

# Processing limits
MAX_AUDIO_DURATION = 600  # 10 minutes in seconds
MIN_AUDIO_DURATION = 10   # 10 seconds minimum
MAX_ONSET_COUNT = 10000   # Maximum onsets to process